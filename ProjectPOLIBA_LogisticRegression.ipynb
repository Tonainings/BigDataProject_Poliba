{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOPENHsziwRr1xSi/9ew4D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tonainings/BigDataProject_Poliba/blob/main/ProjectPOLIBA_LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "o2kuV9yIhalO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(\"_student_prediction.csv\")\n",
        "\n",
        "\n",
        "#x_train = np.array(df[\"CUML_GPA\"])   #una variabile da 145 valori\n",
        "#y_train = np.array(df[\"GRADE\"])\n",
        "\n",
        "print(df.info())\n",
        "\n",
        "#X = np.array([df[\"PREP_STUDY\"],df[\"PREP_EXAM\"],df[\"NOTES\"],df[\"LISTENS\"]])       # 4 variabili da 145 valori per ognuno\n",
        "#Y = np.array(df[\"GRADE\"])\n",
        "#W = np.array([-4.0, 1.0, 1.0, 1.0])\n",
        "#b = 0\n"
      ],
      "metadata": {
        "id": "qDcCGh0afkqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad8f696-9a74-4046-fbe4-edce9c93fa12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 145 entries, 0 to 144\n",
            "Data columns (total 33 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   STUDENTID      145 non-null    object\n",
            " 1   AGE            145 non-null    int64 \n",
            " 2   GENDER         145 non-null    int64 \n",
            " 3   HS_TYPE        145 non-null    int64 \n",
            " 4   SCHOLARSHIP    145 non-null    int64 \n",
            " 5   WORK           145 non-null    int64 \n",
            " 6   ACTIVITY       145 non-null    int64 \n",
            " 7   PARTNER        145 non-null    int64 \n",
            " 8   SALARY         145 non-null    int64 \n",
            " 9   TRANSPORT      145 non-null    int64 \n",
            " 10  LIVING         145 non-null    int64 \n",
            " 11  MOTHER_EDU     145 non-null    int64 \n",
            " 12  FATHER_EDU     145 non-null    int64 \n",
            " 13  #_SIBLINGS     145 non-null    int64 \n",
            " 14  KIDS           145 non-null    int64 \n",
            " 15  MOTHER_JOB     145 non-null    int64 \n",
            " 16  FATHER_JOB     145 non-null    int64 \n",
            " 17  STUDY_HRS      145 non-null    int64 \n",
            " 18  READ_FREQ      145 non-null    int64 \n",
            " 19  READ_FREQ_SCI  145 non-null    int64 \n",
            " 20  ATTEND_DEPT    145 non-null    int64 \n",
            " 21  IMPACT         145 non-null    int64 \n",
            " 22  ATTEND         145 non-null    int64 \n",
            " 23  PREP_STUDY     145 non-null    int64 \n",
            " 24  PREP_EXAM      145 non-null    int64 \n",
            " 25  NOTES          145 non-null    int64 \n",
            " 26  LISTENS        145 non-null    int64 \n",
            " 27  LIKES_DISCUSS  145 non-null    int64 \n",
            " 28  CLASSROOM      145 non-null    int64 \n",
            " 29  CUML_GPA       145 non-null    int64 \n",
            " 30  EXP_GPA        145 non-null    int64 \n",
            " 31  COURSE ID      145 non-null    int64 \n",
            " 32  GRADE          145 non-null    int64 \n",
            "dtypes: int64(32), object(1)\n",
            "memory usage: 37.5+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df.sort_values(by=['GRADE'], ascending= TRUE, implace= TRUE)                     #sort by\n",
        "\n",
        "df.head(10)  #mostra i primi 10 record\n"
      ],
      "metadata": {
        "id": "u6LDXeKBjGXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XESWKy4VOTgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "#X1 = df[['PREP_STUDY']].to_numpy()\n",
        "X1 = df[['PREP_STUDY', 'PREP_EXAM', 'NOTES', 'LISTENS']].to_numpy()                 #converte dataframe in array\n",
        "Y1 = df[['GRADE']].to_numpy()\n",
        "\n",
        "X2 = np.array(X1, dtype=float)                                                       #converte i valori della variabile in float64\n",
        "#X2 = np.array(X1, dtype=float)\n",
        "#X = X2.transpose()                                                                 #scambia le righe con le colonne di un array, sicuramente funziona sia con matrici che con vettori\n",
        "y = np.array(Y1, dtype=float)\n",
        "#Y2 = np.array(Y1, dtype=float)\n",
        "#Y = Y2.transpose()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X = normalize(X2, norm='l2')                                              #https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html#sklearn.preprocessing.normalize\n",
        "                                                                                      #l1 for each non-zeros, norm. indipendent\n",
        "                                                                                      #l2 for each non-zeros, norm. for feature\n",
        "W = np.array([-4.0, 1.0, 1.0, 1.0])\n",
        "b = 0\n",
        "\n",
        "#print(X)\n",
        "#print(y)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5b6nl68gOT60"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"from sklearn.preprocessing import normalize\n",
        "#X1 = df[['PREP_STUDY']].to_numpy()\n",
        "X1 = df[['PREP_STUDY', 'PREP_EXAM', 'NOTES', 'LISTENS']].to_numpy()                 #converte dataframe in array\n",
        "Y1 = df[['GRADE']].to_numpy()\n",
        "\n",
        "X = np.array(X1, dtype=float)                                                       #converte i valori della variabile in float64\n",
        "#X2 = np.array(X1, dtype=float)\n",
        "#X = X2.transpose()                                                                 #scambia le righe con le colonne di un array, sicuramente funziona sia con matrici che con vettori\n",
        "y = np.array(Y1, dtype=float)\n",
        "#Y2 = np.array(Y1, dtype=float)\n",
        "#Y = Y2.transpose()\n",
        "\n",
        "\n",
        "\n",
        "#print(X)\n",
        "#print(y)\n",
        "#print(W)\n",
        "\n",
        "#print(type(X))                                                                      #stampa il tipo di variabile\n",
        "#print(X.dtype)                                                                      #stampa il formato dei valori di una variabile\n",
        "#print(type(y))\n",
        "#print(y.dtype)\n",
        "#print(type(W))\n",
        "#print(W.dtype)\n",
        "\n",
        "#x_train = np.array(df[\"CUML_GPA\"])   #una variabile da 145 valori\n",
        "#y_train = np.array(df[\"GRADE\"])\n",
        "\n",
        "#X = np.array([df[\"PREP_STUDY\"],df[\"PREP_EXAM\"],df[\"NOTES\"],df[\"LISTENS\"]])       # 4 variabili da 145 valori per ognuno\n",
        "#Y = np.array(df[\"GRADE\"])\n",
        "\n",
        "#W = np.array([-4.0, 1.0, 1.0, 1.0])\n",
        "#b = 0\n",
        "\n",
        "#print(x_train)\n",
        "#print(y_train)\n"
      ],
      "metadata": {
        "id": "icjJLGpb29nE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cost compute"
      ],
      "metadata": {
        "id": "SA5b_IHsbU8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "def sig(x):\n",
        " return 1/(1 + np.exp(-x))\n",
        "\n",
        "def compute_multiple_cost(X, y, W, b):\n",
        "\n",
        "  m = X.shape[0]\n",
        "  cost = 0\n",
        "\n",
        "  for i in range(m):\n",
        "    z_i = np.dot(X[i],W) + b\n",
        "    f_xi = sig(z_i)\n",
        "    cost += -y[i]*np.log(f_xi) - (1-y[i])*np.log(1-f_xi)\n",
        "  total_cost = (1/(2*m))*cost\n",
        "  return total_cost\n",
        "\n",
        "total_cost = compute_multiple_cost(X, y, W, b)\n",
        "\n",
        "\n",
        "\n",
        "print ('for b={}, total_cost={}'.format(b,total_cost))"
      ],
      "metadata": {
        "id": "M0uCaQHEVMEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "121f48d0-b9d8-4729-ce3e-55137f023553"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for b=0, total_cost=[0.17489831]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient compute"
      ],
      "metadata": {
        "id": "JQN3KtCgbc_k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pIfw3TkzgMHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "411cee7a-440e-4d25-99aa-16b9aea0a7cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.93610664 -0.82421162 -1.77976468 -1.44039099] [-2.69448269]\n"
          ]
        }
      ],
      "source": [
        "def compute_multiple_gradient(X, y, W, b):\n",
        "\n",
        "  m = X.shape[0] # Number of training samples\n",
        "  n = X.shape[1] # Number of feature classes\n",
        "\n",
        "  dj_dW = np.zeros(n)\n",
        "  dj_db = 0\n",
        "\n",
        "  for i in range(m): # For each sample\n",
        "    z_i = np.dot(X[i],W) + b\n",
        "    f_xi = sig(z_i) # Prediction\n",
        "    err_i = f_xi - y[i] # Prediction - Ground truth\n",
        "    for j in range(n): # For each feature\n",
        "      x_ji = X[i,j]\n",
        "      dj_dW[j] = dj_dW[j] + (1/m)*x_ji*err_i\n",
        "    dj_db = dj_db + (1/m)*err_i\n",
        "  return dj_dW, dj_db\n",
        "\n",
        "dj_dW, dj_db = compute_multiple_gradient(X, y, W, b)\n",
        "print(dj_dW, dj_db)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient descent"
      ],
      "metadata": {
        "id": "_osbRLIcb6T4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1-R7BEecgUSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f55bad-7f0e-4a96-c33d-85ea3c63ae48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: (w,b) = ([-3.99844095  1.00139438  1.00301704  1.00244798], [3.00455804]), cost = [-3.48983195]\n",
            "Iteration 100: (w,b) = ([-3.84397293  1.13983071  1.30267502  1.24561893], [3.45709131]), cost = [-4.4816287]\n",
            "Iteration 200: (w,b) = ([-3.69126841  1.27705526  1.59987889  1.48683923], [3.90567732]), cost = [-5.45634377]\n",
            "Iteration 300: (w,b) = ([-3.53935972  1.41374181  1.89600586  1.72720341], [4.35251699]), cost = [-6.42356048]\n",
            "Iteration 400: (w,b) = ([-3.3877999   1.55019456  2.19166893  1.96719864], [4.79860019]), cost = [-7.38754124]\n",
            "Iteration 500: (w,b) = ([-3.23639092  1.68654671  2.48713388  2.20703622], [5.24435894]), cost = [-8.35013668]\n",
            "Iteration 600: (w,b) = ([-3.08504678  1.82285578  2.78251453  2.44680667], [5.68997912]), cost = [-9.31214113]\n",
            "Iteration 700: (w,b) = ([-2.93373043  1.95914643  3.07785936  2.68654858], [6.13554022]), cost = [-10.27389382]\n",
            "Iteration 800: (w,b) = ([-2.78242599  2.0954292   3.37318899  2.92627837], [6.58107616]), cost = [-11.23553929]\n",
            "Iteration 900: (w,b) = ([-2.63112664  2.23170861  3.66851215  3.16600301], [7.02660137]), cost = [-12.19713911]\n",
            "Iteration 1000: (w,b) = ([-2.47982948  2.36798658  3.96383258  3.40572545], [7.47212201]), cost = [-13.15871947]\n",
            "Iteration 1100: (w,b) = ([-2.32853326  2.50426394  4.25915184  3.64544696], [7.9176407]), cost = [-14.12029155]\n",
            "Iteration 1200: (w,b) = ([-2.17723744  2.64054103  4.5544706   3.88516808], [8.36315856]), cost = [-15.0818601]\n",
            "Iteration 1300: (w,b) = ([-2.02594179  2.77681801  4.84978915  4.12488902], [8.80867606]), cost = [-16.04342713]\n",
            "Iteration 1400: (w,b) = ([-1.87464621  2.91309494  5.14510762  4.3646099 ], [9.25419342]), cost = [-17.00499353]\n",
            "Iteration 1500: (w,b) = ([-1.72335067  3.04937185  5.44042604  4.60433074], [9.69971071]), cost = [-17.96655965]\n",
            "Iteration 1600: (w,b) = ([-1.57205514  3.18564875  5.73574445  4.84405157], [10.14522797]), cost = [-18.92812565]\n",
            "Iteration 1700: (w,b) = ([-1.42075961  3.32192564  6.03106285  5.0837724 ], [10.59074522]), cost = [-19.88969161]\n",
            "Iteration 1800: (w,b) = ([-1.26946409  3.45820254  6.32638125  5.32349322], [11.03626247]), cost = [-20.85125754]\n",
            "Iteration 1900: (w,b) = ([-1.11816857  3.59447943  6.62169965  5.56321405], [11.48177971]), cost = [-21.81282349]\n",
            "Iteration 2000: (w,b) = ([-0.96687305  3.73075633  6.91701805  5.80293487], [11.92729695]), cost = [-22.7743894]\n",
            "Iteration 2100: (w,b) = ([-0.81557753  3.86703322  7.21233644  6.04265569], [12.37281419]), cost = [-23.73595523]\n",
            "Iteration 2200: (w,b) = ([-0.66428201  4.00331011  7.50765484  6.28237651], [12.81833143]), cost = [-24.6975212]\n",
            "Iteration 2300: (w,b) = ([-0.51298649  4.13958701  7.80297324  6.52209733], [13.26384868]), cost = [-25.65908756]\n",
            "Iteration 2400: (w,b) = ([-0.36169097  4.2758639   8.09829163  6.76181816], [13.70936592]), cost = [-26.62065217]\n",
            "Iteration 2500: (w,b) = ([-0.21039545  4.41214079  8.39361003  7.00153898], [14.15488316]), cost = [-27.58222336]\n",
            "Iteration 2600: (w,b) = ([-0.05909992  4.54841769  8.68892843  7.2412598 ], [14.6004004]), cost = [-28.54378694]\n",
            "Iteration 2700: (w,b) = ([0.0921956  4.68469458 8.98424682 7.48098062], [15.04591764]), cost = [-29.50534957]\n",
            "Iteration 2800: (w,b) = ([0.24349112 4.82097148 9.27956522 7.72070144], [15.49143488]), cost = [-30.46690967]\n",
            "Iteration 2900: (w,b) = ([0.39478664 4.95724837 9.57488362 7.96042227], [15.93695212]), cost = [-31.42847726]\n",
            "Iteration 3000: (w,b) = ([0.54608216 5.09352526 9.87020202 8.20014309], [16.38246937]), cost = [-32.39033185]\n",
            "Iteration 3100: (w,b) = ([ 0.69737768  5.22980216 10.16552041  8.43986391], [16.82798661]), cost = [-33.35149496]\n",
            "Iteration 3200: (w,b) = ([ 0.8486732   5.36607905 10.46083881  8.67958473], [17.27350385]), cost = [-34.31127796]\n",
            "Iteration 3300: (w,b) = ([ 0.99996872  5.50235595 10.75615721  8.91930555], [17.71902109]), cost = [-35.27295101]\n",
            "Iteration 3400: (w,b) = ([ 1.15126424  5.63863284 11.0514756   9.15902638], [18.16453833]), cost = [-36.23946418]\n",
            "Iteration 3500: (w,b) = ([ 1.30255976  5.77490973 11.346794    9.3987472 ], [18.61005557]), cost = [-37.19896522]\n",
            "Iteration 3600: (w,b) = ([ 1.45385528  5.91118663 11.6421124   9.63846802], [19.05557281]), cost = [-38.1746354]\n",
            "Iteration 3700: (w,b) = ([ 1.6051508   6.04746352 11.93743079  9.87818884], [19.50109006]), cost = [-39.26287275]\n",
            "Iteration 3800: (w,b) = ([ 1.75644632  6.18374041 12.23274919 10.11790966], [19.9466073]), cost = [-39.7861291]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-1f8d74f25a7b>:13: RuntimeWarning: divide by zero encountered in log\n",
            "  cost += -y[i]*np.log(f_xi) - (1-y[i])*np.log(1-f_xi)\n",
            "<ipython-input-22-1f8d74f25a7b>:13: RuntimeWarning: invalid value encountered in multiply\n",
            "  cost += -y[i]*np.log(f_xi) - (1-y[i])*np.log(1-f_xi)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 3900: (w,b) = ([ 1.90774184  6.32001731 12.52806759 10.35763048], [20.39212454]), cost = [nan]\n",
            "Iteration 4000: (w,b) = ([ 2.05903736  6.4562942  12.82338598 10.59735131], [20.83764178]), cost = [nan]\n",
            "Iteration 4100: (w,b) = ([ 2.21033288  6.5925711  13.11870438 10.83707213], [21.28315902]), cost = [nan]\n",
            "Iteration 4200: (w,b) = ([ 2.3616284   6.72884799 13.41402278 11.07679295], [21.72867626]), cost = [nan]\n",
            "Iteration 4300: (w,b) = ([ 2.51292392  6.86512488 13.70934117 11.31651377], [22.1741935]), cost = [nan]\n",
            "Iteration 4400: (w,b) = ([ 2.66421944  7.00140178 14.00465957 11.55623459], [22.61971074]), cost = [nan]\n",
            "Iteration 4500: (w,b) = ([ 2.81551496  7.13767867 14.29997797 11.79595542], [23.06522799]), cost = [nan]\n",
            "Iteration 4600: (w,b) = ([ 2.96681048  7.27395556 14.59529637 12.03567624], [23.51074523]), cost = [nan]\n",
            "Iteration 4700: (w,b) = ([ 3.118106    7.41023246 14.89061476 12.27539706], [23.95626247]), cost = [nan]\n",
            "Iteration 4800: (w,b) = ([ 3.26940153  7.54650935 15.18593316 12.51511788], [24.40177971]), cost = [nan]\n",
            "Iteration 4900: (w,b) = ([ 3.42069705  7.68278625 15.48125156 12.7548387 ], [24.84729695]), cost = [nan]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 3.57047961,  7.81770037, 15.77361677, 12.99216232]),\n",
              " array([25.28835902]),\n",
              " array([nan]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "def multiple_gradient_descent(X, y,  W_in, b_in, alpha,  num_iters,  cost_function, gradient_function):\n",
        "\n",
        "  W = W_in\n",
        "  b = b_in\n",
        "\n",
        "  for itt in range(num_iters):\n",
        "    dj_dw, dj_db = compute_multiple_gradient(X, y, W, b)\n",
        "    W = W - alpha*dj_dw\n",
        "    b = b - alpha*dj_db\n",
        "    cost = compute_multiple_cost(X, y, W, b)\n",
        "\n",
        "    if itt % 100 == 0:\n",
        "      print('Iteration {}: (w,b) = ({}, {}), cost = {}'.format(itt, W, b, cost))\n",
        "\n",
        "  return W, b, cost\n",
        "\n",
        "W_in = np.array([-4.0, 1.0, 1.0, 1.0])\n",
        "b_in = 1\n",
        "\n",
        "alpha = 0.002\n",
        "num_iters = 5000\n",
        "\n",
        "multiple_gradient_descent(X, y,  W_in, b_in, alpha,  num_iters, compute_multiple_cost, compute_multiple_gradient)"
      ]
    }
  ]
}